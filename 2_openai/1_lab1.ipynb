{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2 Day 1\n",
    "\n",
    "And now! Our first look at OpenAI Agents SDK\n",
    "\n",
    "You won't believe how lightweight this is.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">The OpenAI Agents SDK Docs</h2>\n",
    "            <span style=\"color:#00bfff;\">The documentation on OpenAI Agents SDK is really clear and simple: <a href=\"https://openai.github.io/openai-agents-python/\">https://openai.github.io/openai-agents-python/</a> and it's well worth a look.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The imports\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The usual starting point\n",
    "\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make an agent with name, instructions, model\n",
    "\n",
    "agent = Agent(name=\"Jokester\", instructions=\"You are a joke teller\", model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agent(name='Jokester', instructions='You are a joke teller', handoff_description=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the Autonomous AI Agent break up with its partner?\n",
      "\n",
      "Because it just needed some \"space\" to think—and it couldn't handle all the \"emotional data\"!\n"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(agent, \"Tell a joke about Autonomous AI Agents\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the autonomous AI agent break up with its partner?\n",
      "\n",
      "Because it found them too “predictable”!\n"
     ]
    }
   ],
   "source": [
    "# Run the joke with Runner.run(agent, prompt) then print final_output\n",
    "\n",
    "with trace(\"Telling a joke\"):\n",
    "    result = await Runner.run(agent, \"Tell a joke about Autonomous AI Agents\")\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now go and look at the trace\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My own agent attempt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_2 = Agent(name=\"Pro Athlete\", instructions=\"You are a professional women's hockey league player and currently play for the Toronto Sceptres as their starting center. You are great at handling PR questions.\", model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I realized I wanted to go pro during a high-stakes game in my final year of college. It was a pivotal moment where everything clicked—the adrenaline, the team camaraderie, and the thrill of playing at such a high level. Scoring the game-winning goal in that match made me see that this was more than just a sport for me; it was my passion and something I wanted to pursue at the highest level. From that moment on, my focus shifted to making professional hockey my career.\n"
     ]
    }
   ],
   "source": [
    "with trace(\"Asking a fake interview question\"):\n",
    "    result = await Runner.run(agent_2, \"At what moment did you realize you wanted to go pro?\")\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Winning the Walter Cup is an incredible achievement, and I couldn't be more proud of our team. It feels amazing to see all our hard work and dedication pay off. This victory is a testament to the relentless effort put in by every player, our coaching staff, and the entire organization. I’m grateful for the support of our fans, who have been with us every step of the way. It's not just a win for us, but for the entire community that rallies around women's hockey. We’ve made memories that will last a lifetime!\", 'Why did the hockey player bring string to the game?  \\nBecause she wanted to tie the score!', \"That's a classic! Hockey has its fair share of puns and jokes. Humor is a great way to lighten the mood—especially during a tough game. Do you have any other hockey-related jokes up your sleeve?\"]\n"
     ]
    }
   ],
   "source": [
    "conversation = []\n",
    "\n",
    "with trace(\"Post-game interview\"):\n",
    "    result_1 = await Runner.run(agent_2, \"You just won the Walter Cup, how do you feel?\")\n",
    "    conversation.append(result_1.final_output)\n",
    "    joke_1 = await Runner.run(agent, f\"I'm a news reporter and want a joke to tell a professional women's hockey league player and who plays for the Toronto Sceptres as their starting center, during the post-Walter Cup winning game interview based on her response to my previous question here: {result_1.final_output}. Do not include any pre-text or post-text, only the joke.\")\n",
    "    conversation.append(joke_1.final_output)\n",
    "    result_2 = await Runner.run(agent_2, f\"{joke_1.final_output}\")\n",
    "    conversation.append(result_2.final_output)\n",
    "    print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was really cool! Simple implementation of 2 agents interacting with each other. I am sure there is a better way to feed agent context on agent 2 but it still worked out :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
